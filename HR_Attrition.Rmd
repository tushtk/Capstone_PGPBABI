---
title: "HR Employee Attrition Data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Adding all necessary libraries
```{r pressure, echo=FALSE}
#install.packages(c("SDMTools",'pROC','Hmisc'))
library(SDMTools)
library(ROCR)
library(Hmisc)
library(dummies)
library(ggplot2)
library(dplyr)
library(pROC)
library(neuralnet)
library(rpart)
library(rpart.plot)

getwd()

```
1
# a) Data Import (Target variable is "Attrition" column)
```{r}
getwd()
attr_data=read.csv("Data/1452762979_586__HR_Employee_Attrition_Data.csv")
str(attr_data)
dim(attr_data)

```
# b) Split the data in Dev & Hold Out sample (70:30)

```{r}
set.seed(1234)
pd = sample(2,nrow(attr_data),replace = TRUE, prob = c(.7,0.3))
A.train  = attr_data[pd==1,]
A.test = attr_data[pd!=1 ,]
dim(A.train)
dim(A.test)
```
# c) Perform Exploratory Data Analysis
Checking the dependent variable : Attrition counts
```{r}
table(A.train$Attrition)
```
16% Attrition rate in the training dataset.

Age wise distribution
```{r}
mean(A.train$Age)
A.train %>% 
  ggplot(aes(x=Age,group =Attrition,color = Attrition)) +
  geom_histogram(stat="count" )
```

```{r}
table(A.train$Education,A.train$Attrition) ->tE

# Rate of attrition across 5 Education levels
rowSums(tE)/tE[,2] 

# Average Rate of attrition is 6.6 
mean(rowSums(tE)/tE[,2])

A.train %>% 
  ggplot(aes(x=Education,group =Attrition,color = Attrition)) +
  geom_histogram(stat="count" ,fill = "light blue")
```
#Adding dummy fields for categorical variables
```{r}
A.train.dummies <- dummy.data.frame(A.train[,-2],sep='_') 
A.train.dummies <- cbind(Attrition =A.train$Attrition, A.train.dummies)
str(A.train)
str(A.train.dummies)
```

# d) Identify columns which are of no use. drop those columns
Logistic modeling to identify significance of fields 

fields removed - 
  over18 (Factor w/ 1 level)
  standardHours (All have same value = 80)
  EmployeeNumber
  EmployeeCount
  
```{r}
table(A.train.dummies$StandardHours ==80)
table(A.train$Department)
table(A.train$JobRole)
table(A.train$MaritalStatus)

# Removing irrelavant fields
drops =c("StandardHours","EmployeeNumber","EmployeeCount")
         
# Removing dummies to avoid multi collinearity 
drops_a = c("BusinessTravel_Travel_Rarely",                  "Department_Human Resources",
    "EducationField_Other","Gender_Male","JobRole_Human Resources",
    "MaritalStatus_Divorced","OverTime_No")
A.train.dummies <- 
  A.train.dummies[,!names(A.train.dummies) %in% drops] 
A.train.dummies <- 
  A.train.dummies[,!names(A.train.dummies) %in% drops_a] 

str(A.train.dummies)
glm(Attrition~.,data=A.train.dummies, family = binomial)  -> lgm1
summary(lgm1)
```
# Removing insignificant fields from the first model based on Pr vlaue & significance
```{r}
drops_l1 = c("DailyRate","Department_Research & Development","Department_Sales" , "EducationField_Human Resources",
"EducationField_Life Sciences","EducationField_Marketing",
"EducationField_Medical","HourlyRate",
"JobRole_Healthcare Representative" ,
"JobRole_Laboratory Technician", 
"JobRole_Manager" ,
"JobRole_Manufacturing Director",
"JobRole_Research Director",
"JobRole_Research Scientist",
"JobRole_Sales Executive",
"JobRole_Sales Representative","MonthlyIncome","MonthlyRate",
"PercentSalaryHike","PerformanceRating")

A.train.dummies <- 
  A.train.dummies[,!names(A.train.dummies) %in% drops_l1] 
```
# Remodeling 
```{r}
glm(Attrition~.,data=A.train.dummies, family = binomial)  -> lgm2
summary(lgm2)
```
# logistic model AIC = 1352.3 

# Checking for multicollinearity
```{r}
#vif(lgm2)
```

# Prediction using logistic model on training dataset 
```{r}
A.train.d <- dummy.data.frame(A.train[,-2],sep="_")

str(A.train.dummies)
predict(lgm2,A.train.d,type='resp' ) -> lp1
head(lp1) 
table(Actual = A.train$Attrition,Predicted = ifelse(lp1>=.5,1,0)) -> train_acc
train_acc
# Accuracy of correct prediction - 87.22% 
sum(diag(train_acc))/sum(train_acc)

# Accuracy of prediction positive Attrition - 41.3%
train_acc[4]/(train_acc[2] + train_acc[4])

head(A.train$Attrition)
#pred_obj1 = prediction(lp1,A.train$Attrition)
#perf1.auc = performance(pred_obj1,"auc")
#perf1.acc = performance(pred_obj1,"acc")
#plot(perf1.acc)
#perf1.auc
#attr(perf1.auc,"y.values")
```
For the logistic model - Area Under the curve -  .85677
# Testing the model using the test data 
```{r}
A.test.d <- dummy.data.frame(A.test[,-2],sep="_")

str(A.test.d)
predict(lgm2,A.test.d,type='response' ) -> test_lp1

table(Actual = A.test$Attrition,Predicted = ifelse(test_lp1>=.5,1,0)) -> test_acc
test_acc
# Accuracy of correct prediction - 87.67% 
sum(diag(test_acc))/sum(test_acc)

# Accuracy of prediction positive Attrition - 41.3%
test_acc[4]/(test_acc[2] + test_acc[4])

#test_pred_obj1 = prediction(test_lp1,A.test$Attrition)
#test_perf1.auc = performance(test_pred_obj1,"auc")
#test_perf1.acc = performance(test_pred_obj1,"acc")
#plot(test_perf1.acc)
#attr(test_perf1.auc,"y.values")
```
For the logistic model - Area Under the curve for test data -  .82764

# e) Write Hypothesis and validate the Hypothesis

Inorder to model the data using neural network 
model equation  - 
Y =   0  { if W.X + b <= 0 
      1  { if W.X + b > 0 
      
X is the input matrix 
W is weightage matrix 
      
H0 :  W = 0  (Null hypothesis)
H1 :  W != 0 

To reject the null hypothesis we need to build a neural network model and verify the coefficients in the model have pvlaue  < .05

# f) Build Neural Network Model (Development sample)
```{r}
# adding dummies in train data and changing naming
# fields with spaces, '&' and '-' are removed because neuralnet() command is giving an error 
A.train.nn <- dummy.data.frame(A.train[,-2],sep="_")

# Removing irrelavant fields
#drops =c("StandardHours","EmployeeNumber","EmployeeCount")
#A.train.nn <- A.train.nn [,!names(A.train.nn) %in% drops] 


names(A.train.nn) <- gsub(" ","",names(A.train.nn))
names(A.train.nn) <- gsub("&","",names(A.train.nn))
names(A.train.nn) <- gsub("-","",names(A.train.nn))
str(A.train.nn)
paste(names(A.train.nn),collapse = "+") ->s 
s
paste('Attrition ~',s,sep='') ->s

A.train.nn$Attrition = ifelse(A.train$Attrition=="Yes",1,0)
neuralnet(as.formula(s),data = A.train.nn , act.fct = "logistic",hidden=10,err.fct = "ce",linear.output = F) -> nn
summary(nn)
head(nn$result.matrix)
```
Error in the neural network - 901 

# Adding more hidden layers in the nn 
```{r}
neuralnet(as.formula(s),data = A.train.nn , act.fct = "logistic",hidden=50,err.fct = "ce",linear.output = F) -> nn50
head(nn50$result.matrix)
compute(nn50,A.train.nn[,-1]) -> pp_train
table(A.train$Attrition,ifelse(pp_train$net.result>.5,1,0)) ->nn_train
sum(diag(nn_train))/sum(nn_train)

```
Error reduced to 736
Prediction accuracy for training dataset is 82.285%

# g) Validate NN model on Hold Out. If need be improvise
```{r}
# adding dummies in test data and changing naming
# fields with spaces, '&' and '-' are removed because neuralnet() command is giving an error 
A.test.nn <- dummy.data.frame(A.test[,-2],sep="_")
names(A.test.nn) <- gsub(" ","",names(A.test.nn))
names(A.test.nn) <- gsub("&","",names(A.test.nn))
names(A.test.nn) <- gsub("-","",names(A.test.nn))
str(A.test.nn)
paste(names(A.test.nn),collapse = "+") ->s.test
s.test
paste('Attrition ~',s.test,sep='') ->s.test

A.test.nn$Attrition = ifelse(A.test$Attrition=="Yes",1,0)

compute(nn,A.test.nn[,-1]) -> pp
-1*sum(ifelse(A.test.nn==1,log(pp$net.result),log(1-pp$net.result)))

table(A.test$Attrition,ifelse(pp$net.result>.5,1,0)) ->nn_t
sum(diag(nn_t))/sum(nn_t)


head(pp$net.result)
View(cbind(lp1 ,pp$net.result))
```


Neural network has 85.31% accuracy in prediction for test dataset

# h) Build CART Model
```{r}

rpart(Attrition~.,data= A.train,method = 'class') -> At
summary(At)
rpart.plot(At)

```
```{r}
### complexity parameter
printcp(At)
rpart(Attrition~.,data= A.train,method = 'class',control= rpart.control(cp=.001)) -> At1
rpart.plot(At1)
printcp(At1)

0.80747126 + 0.044801279
```
Xerror is the lowest at CP = 0.0076628352 with a standard deviation of 0.044801279, 
```{r}
table(A.train$Attrition,Ap) -> Dt
sum(diag(Dt))/sum(Dt)
```
Training dataset has 89.38% accura
0.80747126 + 0.044801279 =  0.852272539

So at CP = 0.0100574713, the xerror is within 1 SD from the lowest 
# So cutting the  tree at CP = 0.0100574713
```{r}
prune(At1,cp=0.0100574713 ) ->At_final
predict(At_final,A.train,type ='class') ->Ap
table(A.train$Attrition,Ap)

```
Decision tree accuracy of correctly predicting using the train dataset is 89.385%

# i) Validate CART Model
```{r}
predict(At_final,A.test,type ='class') ->Ap_test

table(A.test$Attrition,Ap_test)
table(A.test$Attrition,Ap_test) ->Dt_t
sum(diag(Dt_t))/sum(Dt_t)
table(A.train$Attrition)

```
Test data is correctly predicted with accuracy - 87.76% using decision tree 

# j) Compare NN with CART
```{r}
# table of AUC, Accuracy, AIC for both models for both train and test dataset

##   AUC 
prediction(pp$net.result,A.test.nn$Attrition) ->pred_nn
head(pred1)
perf1 = performance(pred1,"auc")
perf2 = performance(pred2, "auc")
attr(perf1, "y.values")
attr(perf2, "y.values")

```


# k) Combine NN and CART into Ensemble Model 
```{r}
# Average the predicted probability of NN and CART model 
```


# l) Check whether Ensemble Model Performance outperforms the individual CART & NN model
```{r}
# table of AUC, Accuracy, AIC for both models individually and together for both train and test dataset

```